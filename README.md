ğŸŒ **Language:** **English** | [à¸ à¸²à¸©à¸²à¹„à¸—à¸¢](README.th.md)

# DataProfiler

Automated **Data Profiling** tool for PostgreSQL with [dbt-profiler](https://github.com/data-mie/dbt-profiler) style metrics, storing results in ClickHouse.

![Dashboard Screenshot](docs/images/dashboard.png)

## ğŸ¯ Overview

DataProfiler provides:

1. **Automatic Schema Discovery** from PostgreSQL (information_schema)
2. **dbt-profiler Style Metrics** calculation via SQL queries
3. **Result Storage** in ClickHouse for analysis and tracking
4. **Multiple Export Formats**: Markdown, JSON, CSV, Console Table
5. **Web Dashboard** for data visualization (React + TailwindCSS)

## ğŸ“Š Profiled Metrics

For each column, the system collects the following statistics (dbt-profiler compatible):

| Metric                | Description                                 | Condition             |
| --------------------- | ------------------------------------------- | --------------------- |
| `column_name`         | Column name                                 | All columns           |
| `data_type`           | Data type                                   | All columns           |
| `not_null_proportion` | Proportion of non-NULL values (0.00 - 1.00) | All columns           |
| `distinct_proportion` | Proportion of unique values (0.00 - 1.00)   | All columns           |
| `distinct_count`      | Count of unique values                      | All columns           |
| `is_unique`           | Whether all values are unique (true/false)  | All columns           |
| `min` / `max`         | Minimum / Maximum values                    | numeric, date, time\* |
| `avg`                 | Average value                               | numeric\*\*           |
| `median`              | Median value                                | numeric\*\*           |
| `std_dev_population`  | Population standard deviation               | numeric\*\*           |
| `std_dev_sample`      | Sample standard deviation                   | numeric\*\*           |
| `profiled_at`         | Profile timestamp                           | All columns           |

> **\*** `min`/`max` supported for: integer, numeric, float, date, timestamp, time  
> **\*\*** `avg`, `median`, `std_dev` supported for: integer, numeric, float

## ğŸ› ï¸ Requirements

- Python 3.10+
- PostgreSQL
- ClickHouse
- Dependencies:
  - `psycopg2` - PostgreSQL adapter
  - `clickhouse-connect` - ClickHouse client
  - `soda-core-postgres` - Soda Core for PostgreSQL
  - `jinja2` - Template engine
  - `python-dotenv` - Environment variable management

## ğŸ“¦ Installation

1. Clone repository:

```bash
git clone <repository-url>
cd DataProfiler
```

2. Create and activate Virtual Environment:

```bash
# Create venv
python -m venv venv

# Activate (macOS/Linux)
source venv/bin/activate

# Activate (Windows)
venv\Scripts\activate
```

3. Install dependencies:

```bash
pip install -r requirements.txt
```

## âš™ï¸ Configuration

### 1. Create Environment Variables File

Copy `.env.example` to `.env` and edit values:

```bash
cp .env.example .env
```

Edit `.env` file:

```bash
# PostgreSQL Configuration
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_DATABASE=postgres
POSTGRES_USER=postgres
POSTGRES_PASSWORD=your_actual_password
POSTGRES_SCHEMA=public

# ClickHouse Configuration
CLICKHOUSE_HOST=localhost
CLICKHOUSE_PORT=8123
CLICKHOUSE_USER=default
CLICKHOUSE_PASSWORD=your_actual_password
```

> âš ï¸ **Important:** The `.env` file is already git-ignored. No need to worry about committing credentials.

### 2. Soda Core Configuration

Edit `configuration.yml` for Soda Core:

```yaml
data_source my_postgres:
  type: postgres
  host: ${POSTGRES_HOST}
  port: ${POSTGRES_PORT}
  username: ${POSTGRES_USER}
  password: ${POSTGRES_PASSWORD}
  database: ${POSTGRES_DATABASE}
  schema: ${POSTGRES_SCHEMA}
```

## ğŸš€ Usage

### Basic Usage

```bash
# Profile 'users' table (default app/env)
python main.py users

# Profile with Application & Environment context
python main.py users --app order-service --env uat
python main.py users --app order-service --env production

# Profile a specific table
python main.py products
```

### Output Formats

```bash
# Console table (default)
python main.py users --format table

# Markdown (dbt-profiler style)
python main.py users --format markdown

# JSON
python main.py users --format json

# CSV
python main.py users --format csv
```

### Save to File

```bash
python main.py users --format markdown --output profiles/users.md
python main.py users --format json --output profiles/users.json
python main.py users --format csv --output profiles/users.csv
```

### Additional Options

```bash
# Skip storing to ClickHouse
python main.py users --no-store

# Verbose logging
python main.py users -v

# Show help
python main.py --help
```

## ğŸ“ Project Structure

```
DataProfiler/
â”œâ”€â”€ .env.example           # Environment variables template
â”œâ”€â”€ .env                   # Environment variables (git ignored)
â”œâ”€â”€ .gitignore             # Git ignore rules
â”œâ”€â”€ configuration.yml      # Soda Core data source configuration
â”œâ”€â”€ docker-compose.yml     # Docker test environment
â”œâ”€â”€ main.py                # Main entry point
â”œâ”€â”€ init-scripts/          # PostgreSQL init scripts
â”‚   â””â”€â”€ 01-sample-data.sql
â”œâ”€â”€ pytest.ini             # Pytest configuration
â”œâ”€â”€ README.md              # Documentation (English)
â”œâ”€â”€ README.th.md           # Documentation (Thai)
â”œâ”€â”€ requirements.txt       # Python dependencies
â”œâ”€â”€ src/                   # Source code modules
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py          # Configuration management
â”‚   â”œâ”€â”€ exceptions.py      # Custom exceptions
â”‚   â”œâ”€â”€ core/              # Core profiling logic
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ formatters.py  # Output formatters (MD, JSON, CSV)
â”‚   â”‚   â”œâ”€â”€ metrics.py     # dbt-profiler style metrics
â”‚   â”‚   â””â”€â”€ profiler.py    # Legacy Soda Core profiler
â”‚   â””â”€â”€ db/                # Database connections
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ clickhouse.py
â”‚       â””â”€â”€ postgres.py
â”œâ”€â”€ tests/                 # Unit tests
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_config.py
â”‚   â”œâ”€â”€ test_connections.py
â”‚   â”œâ”€â”€ test_metadata.py
â”‚   â””â”€â”€ test_profiler.py
â””â”€â”€ venv/                  # Python virtual environment (git ignored)
```

## ğŸ§ª Testing

```bash
# Activate virtual environment
source venv/bin/activate

# Run tests
pytest

# Run with verbose output
pytest -v

# Run with coverage report
pytest --cov=src --cov-report=term-missing
```

## ğŸ³ Docker Development Environment

For testing, use Docker Compose to set up PostgreSQL and ClickHouse:

```bash
# Start all services
docker-compose up -d

# View logs
docker-compose logs -f

# Check status
docker-compose ps
```

### Sample Data

Docker automatically creates sample data:

| Table      | Description                                           |
| ---------- | ----------------------------------------------------- |
| `users`    | 10 records - User data (with NULL values for testing) |
| `products` | 8 records - Product data                              |

### Stop Services

```bash
# Stop all services
docker-compose down

# Stop and remove all data
docker-compose down -v
```

## ğŸ“Š Dashboard

DataProfiler includes a Web Dashboard for visualizing profile data.

### Features

- **Sidebar Navigation** - Table list with row/column counts
- **Bar Charts** - Not Null Proportion, Distinct Proportion
- **Column Details Table** - All metrics in table format
- **Dark Theme** - Modern UI

### Running the Dashboard

```bash
# 1. Start Backend API (port 5001)
cd dashboard/backend
source ../venv/bin/activate
python app.py

# 2. Start Frontend (port 5173)
cd dashboard/frontend
npm install  # First time only
npm run dev

# 3. Open Browser
open http://localhost:5173
```

### Technology Stack

| Component | Technology         |
| --------- | ------------------ |
| Backend   | Flask + Flask-CORS |
| Frontend  | React + Vite       |
| Styling   | TailwindCSS        |
| Charts    | Recharts           |

## ğŸ“ˆ Grafana Dashboard (Alternative)

This project includes a **Grafana** instance connected to ClickHouse for advanced visualization.

### Features

- **Direct ClickHouse Integration**: No middleware required.
- **Customizable**: Create complex dashboards with SQL queries.
- **Alerting**: Native Grafana alerting support.
- **User Management**: Role-based access control.

### Setup

The Grafana service is included in `docker-compose.yml` and pre-configured with the ClickHouse datasource.

1. Start all services:

   ```bash
   docker-compose up -d
   ```

2. Open Grafana:

   - URL: http://localhost:3000
   - User: `admin`
   - Password: `admin`

3. Create Dashboard:
   - DataSource: **ClickHouse** (pre-configured)
   - Example Query:
     ```sql
     SELECT table_name, max(row_count) as rows
     FROM data_profiles
     WHERE application = 'order-service'
     GROUP BY table_name
     ```

## ğŸ“ License

[MIT License](LICENSE)

## ğŸ¤ Contributing

Pull requests are welcome! For major changes, please open an issue first to discuss.
