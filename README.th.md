üåê **Language:** [English](README.md) | **‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢**

# DataProfiler

‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ó‡∏≥ **Data Profiling** ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥‡∏à‡∏≤‡∏Å **PostgreSQL** ‡πÅ‡∏•‡∏∞ **Microsoft SQL Server** ‡πÅ‡∏ö‡∏ö [dbt-profiler](https://github.com/data-mie/dbt-profiler) style ‡πÅ‡∏•‡∏∞‡∏à‡∏±‡∏î‡πÄ‡∏Å‡πá‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏•‡∏á ClickHouse

![Dashboard Screenshot](docs/images/dashboard.png)

## üéØ ‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°

DataProfiler ‡∏ó‡∏≥‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà:

1. **‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏´‡∏•‡∏≤‡∏¢ Database**: PostgreSQL ‡πÅ‡∏•‡∏∞ Microsoft SQL Server (Azure SQL Edge)
2. **‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Schema** ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥‡∏à‡∏≤‡∏Å database ‡∏ï‡πâ‡∏ô‡∏ó‡∏≤‡∏á (information_schema)
3. **‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Metrics** ‡πÅ‡∏ö‡∏ö dbt-profiler style ‡∏î‡πâ‡∏ß‡∏¢ SQL queries
4. **‡∏à‡∏±‡∏î‡πÄ‡∏Å‡πá‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå** ‡∏•‡∏á ClickHouse ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÅ‡∏•‡∏∞‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°
5. **Export ‡πÑ‡∏î‡πâ‡∏´‡∏•‡∏≤‡∏¢‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö**: Markdown, JSON, CSV, Console Table
6. **Web Dashboard** ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö visualize ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (React + TailwindCSS)
7. **‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á Auto-Increment Overflow** ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏¥‡∏ö‡πÇ‡∏ï‡∏î‡πâ‡∏ß‡∏¢ Linear Regression

## üìä ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà Profile

‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞ Column ‡∏£‡∏∞‡∏ö‡∏ö‡∏à‡∏∞‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏î‡∏±‡∏á‡∏ô‡∏µ‡πâ (dbt-profiler compatible):

| Metric                | ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢                                | Condition             |
| --------------------- | --------------------------------------- | --------------------- |
| `column_name`         | ‡∏ä‡∏∑‡πà‡∏≠ column                             | ‡∏ó‡∏∏‡∏Å column            |
| `data_type`           | ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•                            | ‡∏ó‡∏∏‡∏Å column            |
| `not_null_proportion` | ‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÄ‡∏õ‡πá‡∏ô NULL (0.00 - 1.00) | ‡∏ó‡∏∏‡∏Å column            |
| `distinct_proportion` | ‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏ã‡πâ‡∏≥‡∏Å‡∏±‡∏ô (0.00 - 1.00)    | ‡∏ó‡∏∏‡∏Å column            |
| `distinct_count`      | ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏ã‡πâ‡∏≥‡∏Å‡∏±‡∏ô                    | ‡∏ó‡∏∏‡∏Å column            |
| `is_unique`           | ‡πÄ‡∏õ‡πá‡∏ô unique ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà (true/false)        | ‡∏ó‡∏∏‡∏Å column            |
| `min` / `max`         | ‡∏Ñ‡πà‡∏≤‡∏ï‡πà‡∏≥‡∏™‡∏∏‡∏î / ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î                      | numeric, date, time\* |
| `avg`                 | ‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢                               | numeric\*\*           |
| `median`              | ‡∏Ñ‡πà‡∏≤‡∏°‡∏±‡∏ò‡∏¢‡∏ê‡∏≤‡∏ô                              | numeric\*\*           |
| `std_dev_population`  | Standard deviation (population)         | numeric\*\*           |
| `std_dev_sample`      | Standard deviation (sample)             | numeric\*\*           |
| `profiled_at`         | ‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡∏ó‡∏≥ profile                       | ‡∏ó‡∏∏‡∏Å column            |

> **\*** `min`/`max` ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡πÄ‡∏â‡∏û‡∏≤‡∏∞: integer, numeric, float, date, timestamp, time  
> **\*\*** `avg`, `median`, `std_dev` ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡πÄ‡∏â‡∏û‡∏≤‡∏∞: integer, numeric, float

## üîÆ ‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á Auto-Increment Overflow

DataProfiler ‡∏°‡∏µ‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå **‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á Auto-Increment Column Overflow** ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ß‡πà‡∏≤ Primary Key ‡∏à‡∏∞‡πÄ‡∏ï‡πá‡∏°‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÉ‡∏î

### ‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå

- **‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°‡∏Ñ‡πà‡∏≤‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô**: ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡πà‡∏≤‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô‡∏Ç‡∏≠‡∏á auto-increment columns
- **‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡πà‡∏≤‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î**: ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡πà‡∏≤ max ‡∏ï‡∏≤‡∏° data type (‡πÄ‡∏ä‡πà‡∏ô INT, BIGINT)
- **‡πÄ‡∏õ‡∏≠‡∏£‡πå‡πÄ‡∏ã‡πá‡∏ô‡∏ï‡πå‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô**: ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì capacity ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÑ‡∏õ‡πÅ‡∏•‡πâ‡∏ß
- **‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏¥‡∏ö‡πÇ‡∏ï**: ‡πÉ‡∏ä‡πâ Linear Regression ‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏¢‡πâ‡∏≠‡∏ô‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å ClickHouse
- **‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ß‡∏±‡∏ô‡∏Å‡πà‡∏≠‡∏ô‡πÄ‡∏ï‡πá‡∏°**: ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ß‡πà‡∏≤‡∏≠‡∏µ‡∏Å‡∏Å‡∏µ‡πà‡∏ß‡∏±‡∏ô column ‡∏à‡∏∞‡∏ñ‡∏∂‡∏á‡∏Ñ‡πà‡∏≤‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î
- **‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡πÅ‡∏à‡πâ‡∏á‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô**: CRITICAL (< 30 ‡∏ß‡∏±‡∏ô / > 90%), WARNING (< 90 ‡∏ß‡∏±‡∏ô / > 75%), NORMAL

### Data Types ‡∏ó‡∏µ‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö

| Data Type   | ‡∏Ñ‡πà‡∏≤‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î                 | ‡∏ä‡πà‡∏ß‡∏á                                   |
| ----------- | ------------------------- | -------------------------------------- |
| `smallint`  | 32,767                    | -32,768 ‡∏ñ‡∏∂‡∏á 32,767                     |
| `integer`   | 2,147,483,647             | -2.1 ‡∏û‡∏±‡∏ô‡∏•‡πâ‡∏≤‡∏ô ‡∏ñ‡∏∂‡∏á 2.1 ‡∏û‡∏±‡∏ô‡∏•‡πâ‡∏≤‡∏ô           |
| `bigint`    | 9,223,372,036,854,775,807 | -9.2 ‡∏Ñ‡∏ß‡∏¥‡∏ô‡∏ó‡∏¥‡∏•‡πÄ‡∏•‡∏µ‡∏¢‡∏ô ‡∏ñ‡∏∂‡∏á 9.2 ‡∏Ñ‡∏ß‡∏¥‡∏ô‡∏ó‡∏¥‡∏•‡πÄ‡∏•‡∏µ‡∏¢‡∏ô |
| `serial`    | 2,147,483,647             | 1 ‡∏ñ‡∏∂‡∏á 2.1 ‡∏û‡∏±‡∏ô‡∏•‡πâ‡∏≤‡∏ô                      |
| `bigserial` | 9,223,372,036,854,775,807 | 1 ‡∏ñ‡∏∂‡∏á 9.2 ‡∏Ñ‡∏ß‡∏¥‡∏ô‡∏ó‡∏¥‡∏•‡πÄ‡∏•‡∏µ‡∏¢‡∏ô                 |

#### MSSQL Data Types

| Data Type  | ‡∏Ñ‡πà‡∏≤‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î                 | ‡∏ä‡πà‡∏ß‡∏á                                   |
| ---------- | ------------------------- | -------------------------------------- |
| `tinyint`  | 255                       | 0 ‡∏ñ‡∏∂‡∏á 255                              |
| `smallint` | 32,767                    | -32,768 ‡∏ñ‡∏∂‡∏á 32,767                     |
| `int`      | 2,147,483,647             | -2.1 ‡∏û‡∏±‡∏ô‡∏•‡πâ‡∏≤‡∏ô ‡∏ñ‡∏∂‡∏á 2.1 ‡∏û‡∏±‡∏ô‡∏•‡πâ‡∏≤‡∏ô           |
| `bigint`   | 9,223,372,036,854,775,807 | -9.2 ‡∏Ñ‡∏ß‡∏¥‡∏ô‡∏ó‡∏¥‡∏•‡πÄ‡∏•‡∏µ‡∏¢‡∏ô ‡∏ñ‡∏∂‡∏á 9.2 ‡∏Ñ‡∏ß‡∏¥‡∏ô‡∏ó‡∏¥‡∏•‡πÄ‡∏•‡∏µ‡∏¢‡∏ô |

> **‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏**: ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏ó‡∏±‡πâ‡∏á PostgreSQL SERIAL/BIGSERIAL/IDENTITY columns ‡πÅ‡∏•‡∏∞ MSSQL IDENTITY columns

### ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô

```bash
# PostgreSQL (‡∏Ñ‡πà‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô)
python main.py users --auto-increment

# MSSQL
python main.py test_users -d mssql --auto-increment

# ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏£‡∏∞‡∏¢‡∏∞‡πÄ‡∏ß‡∏•‡∏≤‡∏¢‡πâ‡∏≠‡∏ô‡∏´‡∏•‡∏±‡∏á (‡∏Ñ‡πà‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô: 7 ‡∏ß‡∏±‡∏ô)
python main.py users --auto-increment --lookback-days 14

# ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏£‡∏∞‡∏ö‡∏∏ application ‡πÅ‡∏•‡∏∞ environment
python main.py users --app order-service --env production --auto-increment
```

### ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á Output

```
============================================================
AUTO-INCREMENT OVERFLOW RISK ANALYSIS
============================================================

üü¢ users.id (integer)
   Current: 1,234,567 / 2,147,483,647
   Usage: 0.057479%
   Days until full: 4,521 days
   Growth rate: ~500 IDs/day
============================================================
```

## üõ†Ô∏è Requirements

- Python 3.10+
- PostgreSQL ‡πÅ‡∏•‡∏∞/‡∏´‡∏£‡∏∑‡∏≠ Microsoft SQL Server (Azure SQL Edge ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö ARM64/M1)
- ClickHouse
- Dependencies:
  - `psycopg2` - PostgreSQL adapter
  - `pymssql` - MSSQL adapter
  - `clickhouse-connect` - ClickHouse client
  - `soda-core-postgres` - Soda Core for PostgreSQL
  - `soda-core-sqlserver` - Soda Core for SQL Server
  - `jinja2` - Template engine
  - `python-dotenv` - Environment variable management
  - `numpy` - Numerical computing
  - `scipy` - Scientific computing (Linear Regression)

## üì¶ Installation

1. Clone repository:

```bash
git clone <repository-url>
cd DataProfiler
```

2. ‡∏™‡∏£‡πâ‡∏≤‡∏á Virtual Environment ‡πÅ‡∏•‡∏∞ Activate:

```bash
# ‡∏™‡∏£‡πâ‡∏≤‡∏á venv
python -m venv venv

# Activate (macOS/Linux)
source venv/bin/activate

# Activate (Windows)
venv\Scripts\activate
```

3. ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á Dependencies ‡∏à‡∏≤‡∏Å requirements.txt:

```bash
pip install -r requirements.txt
```

> **‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏:** ‡∏´‡∏≤‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï dependencies ‡πÉ‡∏´‡πâ‡∏£‡∏±‡∏ô `pip install -r requirements.txt --upgrade`

## ‚öôÔ∏è Configuration

### 1. ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå Environment Variables

‡∏Ñ‡∏±‡∏î‡∏•‡∏≠‡∏Å `.env.example` ‡πÄ‡∏õ‡πá‡∏ô `.env` ‡πÅ‡∏•‡∏∞‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏Ñ‡πà‡∏≤‡∏ï‡∏≤‡∏°‡∏à‡∏£‡∏¥‡∏á:

```bash
cp .env.example .env
```

‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÑ‡∏ü‡∏•‡πå `.env`:

```bash
# PostgreSQL Configuration
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_DATABASE=postgres
POSTGRES_USER=postgres
POSTGRES_PASSWORD=your_actual_password
POSTGRES_SCHEMA=public

# ClickHouse Configuration
CLICKHOUSE_HOST=localhost
CLICKHOUSE_PORT=8123
CLICKHOUSE_USER=default
CLICKHOUSE_PASSWORD=your_actual_password
```

> ‚ö†Ô∏è **‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç:** ‡πÑ‡∏ü‡∏•‡πå `.env` ‡∏ñ‡∏π‡∏Å ignore ‡πÇ‡∏î‡∏¢ git ‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏á‡∏ß‡∏•‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á commit credentials

### 2. Soda Core Configuration

‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÑ‡∏ü‡∏•‡πå `configuration.yml` ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Soda Core:

```yaml
data_source my_postgres:
  type: postgres
  host: ${POSTGRES_HOST}
  port: ${POSTGRES_PORT}
  username: ${POSTGRES_USER}
  password: ${POSTGRES_PASSWORD}
  database: ${POSTGRES_DATABASE}
  schema: ${POSTGRES_SCHEMA}

data_source my_mssql:
  type: sqlserver
  host: ${MSSQL_HOST}
  port: ${MSSQL_PORT}
  username: ${MSSQL_USER}
  password: ${MSSQL_PASSWORD}
  database: ${MSSQL_DATABASE}
  schema: ${MSSQL_SCHEMA}
```

## üöÄ Usage

### Basic Usage

```bash
# Profile 'users' table ‡∏à‡∏≤‡∏Å PostgreSQL (‡∏Ñ‡πà‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô)
python main.py users

# Profile ‡∏à‡∏≤‡∏Å MSSQL
python main.py test_users -d mssql

# Profile with Application & Environment context
python main.py users --app order-service --env uat
python main.py users --app order-service --env production

# Profile a specific table
python main.py products
```

### Output Formats

```bash
# Console table (default)
python main.py users --format table

# Markdown (dbt-profiler style)
python main.py users --format markdown

# JSON
python main.py users --format json

# CSV
python main.py users --format csv
```

### Save to File

```bash
python main.py users --format markdown --output profiles/users.md
python main.py users --format json --output profiles/users.json
python main.py users --format csv --output profiles/users.csv
```

### Additional Options

```bash
# Skip storing to ClickHouse
python main.py users --no-store

# Verbose logging
python main.py users -v

# ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó database
python main.py test_users -d mssql           # ‡πÉ‡∏ä‡πâ MSSQL
python main.py users -d postgresql            # ‡πÉ‡∏ä‡πâ PostgreSQL (‡∏Ñ‡πà‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô)

# ‡∏£‡∏ß‡∏°‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå auto-increment overflow
python main.py users --auto-increment
python main.py test_users -d mssql --auto-increment

# ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏£‡∏∞‡∏¢‡∏∞‡πÄ‡∏ß‡∏•‡∏≤‡∏¢‡πâ‡∏≠‡∏ô‡∏´‡∏•‡∏±‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì growth rate
python main.py users --auto-increment --lookback-days 14

# Show help
python main.py --help
```

## üìÅ Project Structure

```
DataProfiler/
‚îú‚îÄ‚îÄ .env.example           # Environment variables template
‚îú‚îÄ‚îÄ .env                   # Environment variables (git ignored)
‚îú‚îÄ‚îÄ .gitignore             # Git ignore rules
‚îú‚îÄ‚îÄ configuration.yml      # Soda Core data source configuration
‚îú‚îÄ‚îÄ docker-compose.yml     # Docker test environment
‚îú‚îÄ‚îÄ main.py                # Main entry point
‚îú‚îÄ‚îÄ init-scripts/          # PostgreSQL init scripts
‚îÇ   ‚îî‚îÄ‚îÄ 01-sample-data.sql
‚îú‚îÄ‚îÄ pytest.ini             # Pytest configuration
‚îú‚îÄ‚îÄ README.md              # Documentation (English)
‚îú‚îÄ‚îÄ README.th.md           # Documentation (Thai)
‚îú‚îÄ‚îÄ requirements.txt       # Python dependencies
‚îú‚îÄ‚îÄ src/                   # Source code modules
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ config.py          # Configuration management
‚îÇ   ‚îú‚îÄ‚îÄ exceptions.py      # Custom exceptions
‚îÇ   ‚îú‚îÄ‚îÄ core/              # Core profiling logic
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ autoincrement_metrics.py  # Auto-increment analysis
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ formatters.py  # Output formatters (MD, JSON, CSV)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ metrics.py     # dbt-profiler style metrics
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ profiler.py    # Legacy Soda Core profiler
‚îÇ   ‚îî‚îÄ‚îÄ db/                # Database connections
‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îú‚îÄ‚îÄ autoincrement.py  # Auto-increment detector (PostgreSQL & MSSQL)
‚îÇ       ‚îú‚îÄ‚îÄ clickhouse.py
‚îÇ       ‚îú‚îÄ‚îÄ connection_factory.py  # Multi-database factory
‚îÇ       ‚îú‚îÄ‚îÄ mssql.py        # MSSQL client
‚îÇ       ‚îî‚îÄ‚îÄ postgres.py
‚îú‚îÄ‚îÄ tests/                 # Unit tests
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ test_autoincrement.py
‚îÇ   ‚îú‚îÄ‚îÄ test_config.py
‚îÇ   ‚îú‚îÄ‚îÄ test_connections.py
‚îÇ   ‚îú‚îÄ‚îÄ test_metadata.py
‚îÇ   ‚îî‚îÄ‚îÄ test_profiler.py
‚îî‚îÄ‚îÄ venv/                  # Python virtual environment (git ignored)
```

## üß™ Testing

### Run All Tests

```bash
# Activate virtual environment
source venv/bin/activate

# Run tests
pytest

# Run with verbose output
pytest -v

# Run with coverage report
pytest --cov=src --cov-report=term-missing
```

## ‚è∞ Control-M Integration

DataProfiler ‡∏°‡∏µ wrapper script ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏£‡∏±‡∏ô‡πÄ‡∏õ‡πá‡∏ô scheduled job ‡∏ö‡∏ô **Control-M** ‡∏´‡∏£‡∏∑‡∏≠ job scheduler ‡∏≠‡∏∑‡πà‡∏ô‡πÜ

### ‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á Wrapper Script

```
scripts/run_profiler.sh
```

### Environment Variables ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Control-M

‡∏Å‡∏≥‡∏´‡∏ô‡∏î environment variables ‡πÄ‡∏´‡∏•‡πà‡∏≤‡∏ô‡∏µ‡πâ‡πÉ‡∏ô Control-M job definition:

#### Database Connection (‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô)

| Variable            | ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢        |
| ------------------- | --------------- |
| `POSTGRES_HOST`     | PostgreSQL host |
| `POSTGRES_PORT`     | PostgreSQL port |
| `POSTGRES_DATABASE` | ‡∏ä‡∏∑‡πà‡∏≠ database   |
| `POSTGRES_USER`     | Username        |
| `POSTGRES_PASSWORD` | Password        |

‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö MSSQL ‡πÉ‡∏ä‡πâ `MSSQL_*` variables ‡πÅ‡∏ó‡∏ô

#### Metrics Backend (‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏ñ‡πâ‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏Å‡πá‡∏ö metrics)

**ClickHouse:**
| Variable | ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ |
|----------|----------|
| `CLICKHOUSE_HOST` | ClickHouse host |
| `CLICKHOUSE_PORT` | ClickHouse HTTP port |
| `CLICKHOUSE_USER` | Username |
| `CLICKHOUSE_PASSWORD` | Password |

**PostgreSQL (‡∏ó‡∏≤‡∏á‡πÄ‡∏•‡∏∑‡∏≠‡∏Å):**
| Variable | ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ |
|----------|----------|
| `PG_METRICS_HOST` | Metrics PostgreSQL host (optional, ‡πÉ‡∏ä‡πâ‡∏Ñ‡πà‡∏≤‡∏à‡∏≤‡∏Å `POSTGRES_*` ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏) |

#### Profiler Options (‡πÑ‡∏°‡πà‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö)

| Variable                  | ‡∏Ñ‡πà‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô  | ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢                                          |
| ------------------------- | ------------ | ------------------------------------------------- |
| `PROFILER_TABLE`          | `users`      | ‡∏ä‡∏∑‡πà‡∏≠ table ‡∏ó‡∏µ‡πà‡∏à‡∏∞ profile                          |
| `PROFILER_FORMAT`         | `table`      | Output format: `table`, `markdown`, `json`, `csv` |
| `PROFILER_OUTPUT_FILE`    | -            | File path ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å output                     |
| `PROFILER_APP`            | `default`    | ‡∏ä‡∏∑‡πà‡∏≠ Application                                  |
| `PROFILER_ENV`            | `production` | ‡∏ä‡∏∑‡πà‡∏≠ Environment                                  |
| `PROFILER_DB_TYPE`        | `postgresql` | Database type: `postgresql`, `mssql`              |
| `METRICS_BACKEND`         | `clickhouse` | Metrics backend: `clickhouse`, `postgresql`       |
| `PROFILER_AUTO_INCREMENT` | `false`      | ‡πÄ‡∏õ‡∏¥‡∏î‡πÉ‡∏ä‡πâ‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå auto-increment                |
| `PROFILER_LOOKBACK_DAYS`  | `7`          | ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ß‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì growth rate                   |
| `PROFILER_NO_STORE`       | `false`      | ‡πÑ‡∏°‡πà‡πÄ‡∏Å‡πá‡∏ö metrics                                   |
| `PROFILER_VERBOSE`        | `false`      | ‡πÄ‡∏õ‡∏¥‡∏î verbose logging                              |
| `PYTHON_PATH`             | `python3`    | Path ‡πÑ‡∏õ‡∏¢‡∏±‡∏á Python executable                      |
| `PROFILER_HOME`           | (script dir) | Path ‡πÑ‡∏õ‡∏¢‡∏±‡∏á DataProfiler installation              |

### Exit Codes

| Code | ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢                                                       |
| ---- | -------------------------------------------------------------- |
| `0`  | ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à                                                         |
| `1`  | ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î configuration (‡∏Ç‡∏≤‡∏î environment variables ‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô) |
| `2`  | ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô (profiler ‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß)                          |
| `3`  | ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î Python environment                                  |

### ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á Control-M Job

#### ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á 1: PostgreSQL + ClickHouse Metrics

```bash
# Job: DATA_PROFILER_USERS_PROD
# Application: DataOps
# Sub-Application: Profiling

# Environment Variables (set ‡πÉ‡∏ô Control-M):
POSTGRES_HOST=db.production.internal
POSTGRES_PORT=5432
POSTGRES_DATABASE=app_db
POSTGRES_USER=profiler_svc
POSTGRES_PASSWORD=<secret>
CLICKHOUSE_HOST=ch.production.internal
CLICKHOUSE_PORT=8123
PROFILER_TABLE=users
PROFILER_APP=order-service
PROFILER_ENV=production
PROFILER_AUTO_INCREMENT=true

# Command:
/opt/dataprofiler/scripts/run_profiler.sh
```

#### ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á 2: MSSQL + PostgreSQL Metrics

```bash
# Job: DATA_PROFILER_ORDERS_MSSQL
# Application: DataOps
# Sub-Application: Profiling

# Environment Variables (set ‡πÉ‡∏ô Control-M):
# Source Database (MSSQL)
MSSQL_HOST=sqlserver.production.internal
MSSQL_PORT=1433
MSSQL_DATABASE=sales_db
MSSQL_USER=profiler_svc
MSSQL_PASSWORD=<secret>
MSSQL_SCHEMA=dbo

# Metrics Storage (PostgreSQL)
METRICS_BACKEND=postgresql
PG_METRICS_HOST=metrics-db.production.internal
PG_METRICS_PORT=5432
PG_METRICS_DATABASE=profiler_metrics
PG_METRICS_USER=metrics_user
PG_METRICS_PASSWORD=<secret>

# Profiler Options
PROFILER_TABLE=orders
PROFILER_DB_TYPE=mssql
PROFILER_APP=sales-service
PROFILER_ENV=production
PROFILER_AUTO_INCREMENT=true
PROFILER_LOOKBACK_DAYS=14

# Command:
/opt/dataprofiler/scripts/run_profiler.sh
```

### Logging

Wrapper script ‡∏™‡∏£‡πâ‡∏≤‡∏á log files ‡πÉ‡∏ô `$PROFILER_HOME/logs/` ‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö:

```
profiler_<CTM_ORDERID>.log
```

Control-M variables `CTM_JOBNAME` ‡πÅ‡∏•‡∏∞ `CTM_ORDERID` ‡∏à‡∏∞‡∏ñ‡∏π‡∏Å‡πÉ‡∏ä‡πâ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö job identification ‡πÉ‡∏ô logs

## üîÑ Workflow

```mermaid
flowchart LR
    A[PostgreSQL] -->|1. Discover Schema| B[DataProfiler]
    B -->|2. Generate SodaCL| C[Soda Core]
    C -->|3. Profile Data| B
    B -->|4. Store Results| D[ClickHouse]
    B -->|5. Auto-Increment Analysis| E[Linear Regression]
    E -->|6. Predict Overflow| D
```

1. **Schema Discovery** - ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Column ‡πÅ‡∏•‡∏∞ Data Type ‡∏à‡∏≤‡∏Å `information_schema`
2. **Template Generation** - ‡∏™‡∏£‡πâ‡∏≤‡∏á SodaCL YAML ‡πÅ‡∏ö‡∏ö Dynamic ‡∏î‡πâ‡∏ß‡∏¢ Jinja2
3. **Data Profiling** - Soda Core ‡∏™‡πÅ‡∏Å‡∏ô‡πÅ‡∏•‡∏∞‡πÄ‡∏Å‡πá‡∏ö‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥
4. **Result Storage** - ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏•‡∏á ClickHouse table `data_profiles`
5. **Auto-Increment Analysis** - ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå auto-increment columns ‡∏î‡πâ‡∏ß‡∏¢ Linear Regression
6. **Overflow Prediction** - ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡πÅ‡∏•‡∏∞‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏•‡∏á `autoincrement_profiles`

## üê≥ Docker Full Stack Environment

‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå‡∏ô‡∏µ‡πâ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÅ‡∏ö‡∏ö Full Stack Containerized ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏£‡∏±‡∏ô‡∏£‡∏∞‡∏ö‡∏ö‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î (DBs, Backend, Frontend, Grafana) ‡πÑ‡∏î‡πâ‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß:

```bash
# Start all services
docker-compose up -d --build
```

### ‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏° Services

| Service        | URL / Port            | ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î                           |
| -------------- | --------------------- | ------------------------------------ |
| **Frontend**   | http://localhost:8080 | Main Data Profiler Dashboard (React) |
| **Grafana**    | http://localhost:3000 | Advanced Visualization (Admin)       |
| **Backend**    | Internal (5001)       | API Service (Flask)                  |
| **ClickHouse** | localhost:8123        | HTTP Interface                       |
| **PostgreSQL** | localhost:5432        | Source Database                      |
| **MSSQL**      | localhost:1433        | Source Database (Azure SQL Edge)     |

### ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô (Credentials)

- **Grafana**: User: `admin`, Pass: `admin`
- **PostgreSQL**: User: `postgres`, Pass: `password123`
- **MSSQL**: User: `sa`, Pass: `YourStrong@Password123`
- **ClickHouse**: User: `default`, Pass: `password123`

### ‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏¥‡πà‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô MSSQL (Azure SQL Edge)

MSSQL ‡πÉ‡∏ä‡πâ Azure SQL Edge ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö ARM64/M1:

```bash
# Start MSSQL container
docker compose up -d mssql

# ‡∏£‡∏≠ ~30 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ ‡∏à‡∏≤‡∏Å‡∏ô‡∏±‡πâ‡∏ô initialize database
python init-scripts/init-mssql.py

# ‡∏ó‡∏î‡∏™‡∏≠‡∏ö profiler
python main.py test_users -d mssql --no-store
```

> **‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏**: Azure SQL Edge ‡πÑ‡∏°‡πà‡∏£‡∏±‡∏ô init scripts ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô PostgreSQL ‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ Python script ‡∏™‡∏£‡πâ‡∏≤‡∏á database

### ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á & ‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö

Docker ‡∏à‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á **100+ records** ‡πÉ‡∏ô PostgreSQL ‡πÉ‡∏´‡πâ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥ (‡∏ï‡∏≤‡∏£‡∏≤‡∏á `users` ‡πÅ‡∏•‡∏∞ `products`) ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡∏±‡πà‡∏á‡∏£‡∏±‡∏ô Profiler ‡∏ú‡πà‡∏≤‡∏ô Docker ‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢:

```bash
# ‡∏£‡∏±‡∏ô profiler ‡∏†‡∏≤‡∏¢‡πÉ‡∏ô backend container
docker-compose exec backend python ../main.py users --app order-service --env production

# ‡∏£‡∏±‡∏ô‡∏û‡∏£‡πâ‡∏≠‡∏° auto-increment analysis
docker-compose exec backend python ../main.py users --auto-increment
```

### ‡∏Å‡∏≤‡∏£‡∏´‡∏¢‡∏∏‡∏î‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô

```bash
docker-compose down -v  # ‡∏´‡∏¢‡∏∏‡∏î‡πÅ‡∏•‡∏∞‡∏•‡∏ö volumes
```

## üìã ClickHouse Schema

### ‡∏ï‡∏≤‡∏£‡∏≤‡∏á `data_profiles`

‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏Å‡πá‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Å‡∏≤‡∏£ profiling:

```sql
CREATE TABLE data_profiles (
    scan_time DateTime DEFAULT now(),
    table_name String,
    column_name String,
    distinct_count Nullable(Int64),
    missing_count Nullable(Int64),
    min Nullable(String),
    max Nullable(String),
    avg Nullable(Float64)
) ENGINE = MergeTree() ORDER BY (scan_time, table_name)
```

### ‡∏ï‡∏≤‡∏£‡∏≤‡∏á `autoincrement_profiles`

‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏Å‡πá‡∏ö‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå auto-increment overflow:

```sql
CREATE TABLE autoincrement_profiles (
    profiled_at DateTime DEFAULT now(),
    application String,
    environment String,
    table_name String,
    column_name String,
    data_type String,
    current_value Int64,
    max_type_value Int64,
    usage_percentage Float64,
    daily_growth_rate Nullable(Float64),
    days_until_full Nullable(Float64),
    alert_status String
) ENGINE = MergeTree() ORDER BY (profiled_at, table_name, column_name)
```

## üìä ‡∏Å‡∏≤‡∏£‡∏û‡∏±‡∏í‡∏ô‡∏≤ Dashboard

‡∏´‡∏≤‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏£‡∏±‡∏ô Dashboard ‡πÅ‡∏ö‡∏ö Manual (‡πÑ‡∏°‡πà‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô Docker) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Å‡∏≤‡∏£‡∏û‡∏±‡∏í‡∏ô‡∏≤:

```bash
# 1. Start Backend API
cd dashboard/backend
python app.py

# 2. Start Frontend
cd dashboard/frontend
npm run dev
# ‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏ó‡∏µ‡πà http://localhost:5173
```

### Technology Stack

| Component | Technology         |
| --------- | ------------------ |
| Backend   | Flask + Flask-CORS |
| Frontend  | React + Vite       |
| Styling   | TailwindCSS        |
| Charts    | Recharts           |

## üìà Grafana Dashboard (‡∏ó‡∏≤‡∏á‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏™‡∏£‡∏¥‡∏°)

‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå‡∏ô‡∏µ‡πâ‡∏°‡∏≤‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏±‡∏ö **Grafana** ‡∏ó‡∏µ‡πà‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ö ClickHouse ‡πÉ‡∏´‡πâ‡πÇ‡∏î‡∏¢‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥

![Grafana Dashboard](docs/images/grafana_dashboard.png)

### ‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå

- **Direct ClickHouse Integration**: ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏ú‡πà‡∏≤‡∏ô middleware
- **Customizable**: ‡∏™‡∏£‡πâ‡∏≤‡∏á Dashboard ‡∏ó‡∏µ‡πà‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô‡∏î‡πâ‡∏ß‡∏¢ SQL
- **Alerting**: ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏£‡∏∞‡∏ö‡∏ö‡πÅ‡∏à‡πâ‡∏á‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô‡∏Ç‡∏≠‡∏á Grafana
- **User Management**: ‡∏£‡∏∞‡∏ö‡∏ö‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô

### ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô

Grafana ‡∏ñ‡∏π‡∏Å‡∏£‡∏ß‡∏°‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô `docker-compose.yml` ‡πÅ‡∏•‡πâ‡∏ß:

1. Start services:

   ```bash
   docker-compose up -d
   ```

2. ‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô Grafana:
   - URL: http://localhost:3000
   - User: `admin`
   - Password: `admin`

3. ‡∏™‡∏£‡πâ‡∏≤‡∏á Dashboard:
   - DataSource: **ClickHouse** (‡∏ñ‡∏π‡∏Å‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÑ‡∏ß‡πâ‡πÅ‡∏•‡πâ‡∏ß)
   - Example Query (Data Profiles):
     ```sql
     SELECT table_name, max(row_count) as rows
     FROM data_profiles
     GROUP BY table_name
     ```
   - Example Query (Auto-Increment Monitoring):
     ```sql
     SELECT
       table_name,
       column_name,
       usage_percentage,
       days_until_full,
       alert_status
     FROM autoincrement_profiles
     ORDER BY profiled_at DESC
     LIMIT 100
     ```

## ‚ö†Ô∏è Limitations

Data Types ‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡πÉ‡∏ô‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö min/max/avg):

- `timestamp`
- `timestamp without time zone`
- `date`
- `bytea`

## üìù License

[MIT License](LICENSE)

## ü§ù Contributing

Pull requests ‡∏¢‡∏¥‡∏ô‡∏î‡∏µ‡∏ï‡πâ‡∏≠‡∏ô‡∏£‡∏±‡∏ö! ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á‡πÉ‡∏´‡∏ç‡πà ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÄ‡∏õ‡∏¥‡∏î Issue ‡∏Å‡πà‡∏≠‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏´‡∏≤‡∏£‡∏∑‡∏≠
